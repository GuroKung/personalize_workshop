{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation on Amazon SageMaker with Neural Networks and MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step SM1: Download ml-100k data  \n",
    "***The data sets are needed to train our Neural Network. We use the 100,000 movie ratings given by users from MovieLens data sets.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  The data sets are needed to train our Factorization Machine. We use the 100,000 movie ratings given by users from MovieLens data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, ndarray\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()\n",
    "s3_prefix = 'movielens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = sess.default_bucket()\n",
    "s3_prefix = 'movielens'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Information\n",
    "*ua.base : data for training*  \n",
    "*ua.test : data for test/validation*  \n",
    "*Headers/columns :* ***user id | item id | rating (1-5) | timestamp***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./ml-100k/ua.base', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "test_df = pd.read_csv('./ml-100k/ua.test', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.read_csv('./ml-100k/u.item', sep='|', names=['item_id','title','release_date','video_release_date','imdb_url','UNKOWN','Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy','Noir','Horror','Musical','Mystery','Romance','SciFi','Thriller','War','Western'],encoding='latin-1')\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_id(fname):\n",
    "    mu = 0\n",
    "    mi = 0\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            tks = line.strip().split('\\t')\n",
    "            if len(tks) != 4:\n",
    "                continue\n",
    "            mu = max(mu, int(tks[0]))\n",
    "            mi = max(mi, int(tks[1]))\n",
    "    return mu + 1, mi + 1\n",
    "max_users, max_items = max_id('./ml-100k/ua.base')\n",
    "(max_users, max_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data to push to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df[['USER_ID','ITEM_ID']].values\n",
    "y_train=train_df[['RATING']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_df[['USER_ID','ITEM_ID']].values\n",
    "y_test=test_df[['RATING']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data ./data/train ./data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/train/train_X.npy', X_train)\n",
    "np.save('./data/train/train_Y.npy', y_train)\n",
    "np.save('./data/test/test_X.npy', X_test)\n",
    "np.save('./data/test/test_Y.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_s3_prefix = '{}/data/train'.format(s3_prefix)\n",
    "testdata_s3_prefix = '{}/data/test'.format(s3_prefix)\n",
    "output_s3 = 's3://{}/{}/models/'.format(s3_bucket, s3_prefix)\n",
    "code_location_s3 = 's3://{}/{}/codes'.format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3 = sess.upload_data(path='./data/train/', bucket=s3_bucket, key_prefix=traindata_s3_prefix)\n",
    "test_s3 = sess.upload_data(path='./data/test/', bucket=s3_bucket, key_prefix=testdata_s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'train':train_s3, 'test': test_s3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "n_latent_factors = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a linear model architecture. This is essentially the same exercise as learning two matrices U,I such that UxI = R and we are back to the original Matrix Facotization problem. We have 3 components, user and item embeddings and a final dot product to evaluate our predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_net():\n",
    "    movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "    movie_embedding = keras.layers.Embedding(max_items, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "    movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "    user_input = keras.layers.Input(shape=[1],name='User')\n",
    "    user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(max_users, n_latent_factors,name='User-Embedding')(user_input))\n",
    "\n",
    "    prod = keras.layers.dot([movie_vec, user_vec],axes=1,name='DotProduct')\n",
    "    model = keras.Model([user_input, movie_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=lin_net()\n",
    "SVG(model_to_dot(net,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lin_net()\n",
    "model.summary()\n",
    "model.fit([X_train[:,0], X_train[:,1]], y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test[:,0],X_test[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([X_test[0:1,0],X_test[0:1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nb=3\n",
    "movie_nb=45\n",
    "model.predict([np.array([user_nb]),np.array([movie_nb])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies={}\n",
    "for index, row in movies_df.iterrows():\n",
    "    movies[int(row['item_id'])]= row['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nb=3\n",
    "score_threshold=2\n",
    "maximum_recommendations=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_movies=[]\n",
    "for movieId in range(max_items):\n",
    "    result_score=model.predict([np.array([user_nb]),np.array([movieId])])\n",
    "    if result_score > score_threshold:\n",
    "        recommended_movies.append([int(movieId),result_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVal(item):\n",
    "    return item[1]\n",
    "recommended_movies=sorted(recommended_movies,key=getVal,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate\n",
    "import tabulate\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = [['<strong>Movie Title</strong>','<strong>Score</strong>']]\n",
    "for i in range(min(maximum_recommendations,len(recommended_movies))):\n",
    "    output_table.append([movies[int(recommended_movies[i][0])],recommended_movies[i][1][0][0]])\n",
    "\n",
    "display(HTML(tabulate.tabulate(output_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet, MXNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxnet_estimator = MXNet('keras_rec.py',\n",
    "                        role=role,\n",
    "                        train_instance_type='ml.c4.xlarge',\n",
    "                        train_instance_count=1,\n",
    "                        framework_version='1.3.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters={'batch-size': 32,'epochs': 10,'learning-rate': 0.1,'embedding-size':32,'max-users':max_users,'max-items':max_items})\n",
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_net():\n",
    "    movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "    movie_embedding = keras.layers.Embedding(max_items, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "    movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "    \n",
    "\n",
    "    user_input = keras.layers.Input(shape=[1],name='User')\n",
    "    user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(max_users, n_latent_factors,name='User-Embedding')(user_input))\n",
    "\n",
    "    concat = keras.layers.concatenate([movie_vec, user_vec],name='Concat')\n",
    "    concat_dropout = keras.layers.Dropout(0.2)(concat)\n",
    "    dense = keras.layers.Dense(200,name='FullyConnected', activation='relu')(concat)\n",
    "    dropout_1 = keras.layers.Dropout(0.2,name='Dropout')(dense)\n",
    "    dense_2 = keras.layers.Dense(100,name='FullyConnected-1',activation='relu')(concat)\n",
    "    dropout_2 = keras.layers.Dropout(0.2,name='Dropout')(dense_2)\n",
    "    dense_3 = keras.layers.Dense(50,name='FullyConnected-2', activation='relu')(dense_2)\n",
    "    dropout_3 = keras.layers.Dropout(0.2,name='Dropout')(dense_3)\n",
    "    dense_4 = keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n",
    "        \n",
    "    result = keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n",
    "    adam = Adam(lr=0.005)\n",
    "    model = keras.Model([user_input, movie_input], result)\n",
    "    model.compile(optimizer=adam,loss= 'mean_absolute_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nl_net()\n",
    "SVG(model_to_dot(net,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nl_net()\n",
    "model.summary()\n",
    "model.fit([X_train[:,0], X_train[:,1]], y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test[:,0],X_test[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxnet_estimator = MXNet('keras_rec_nl.py',\n",
    "                        role=role,\n",
    "                        train_instance_type='ml.c4.xlarge',\n",
    "                        train_instance_count=1,\n",
    "                        framework_version='1.3.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters={'batch-size': 32,'epochs': 10,'learning-rate': 0.1,'embedding-size':32,'max-users':max_users,'max-items':max_items})\n",
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test[:,0],X_test[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nb=3\n",
    "movie_nb=45\n",
    "model.predict([np.array([user_nb]),np.array([movie_nb])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nb=3\n",
    "score_threshold=2\n",
    "maximum_recommendations=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_movies=[]\n",
    "for movieId in range(max_items):\n",
    "    result_score=model.predict([np.array([user_nb]),np.array([movieId])])\n",
    "    if result_score > score_threshold:\n",
    "        recommended_movies.append([int(movieId),result_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVal(item):\n",
    "    return item[1]\n",
    "recommended_movies=sorted(recommended_movies,key=getVal,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = [['<strong>Movie Title</strong>','<strong>Score</strong>']]\n",
    "for i in range(min(maximum_recommendations,len(recommended_movies))):\n",
    "    output_table.append([movies[int(recommended_movies[i][0])],recommended_movies[i][1][0][0]])\n",
    "\n",
    "display(HTML(tabulate.tabulate(output_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
